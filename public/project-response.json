{
  "meta": {
    "total_count": 2
  },
  "items": [
    {
      "id": 12,
      "meta": {
        "type": "projects.ProjectsPage",
        "detail_url": "http://localhost/api/v2/pages/12/",
        "html_url": "http://localhost/projects/audio-fingerprinting/",
        "slug": "audio-fingerprinting",
        "show_in_menus": false,
        "seo_title": "",
        "search_description": "",
        "first_published_at": "2024-01-29T15:27:29.458646Z",
        "alias_of": null,
        "locale": "en"
      },
      "title": "Audio Fingerprinting",
      "project_title": "Audio Fingerprinting",
      "project_sig": "CIPHER",
      "project_slug": "audiofingerprinting",
      "project_authors": "Sai, Ayush, Rehan, Yash",
      "github_url": "https://github.com/creativetimofficial/soft-ui-design-system",
      "project_img_url": "https://images.unsplash.com/photo-1577401159468-3bbc7ee440b5?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D",
      "project_description": "Recognizing a song from a large cluster of audio can&#x27;t be achieved by using brute force to compare an audio sample to every song in the database. In this project we use hashing,a process in which reproducible hash tokens are extracted to save the effort, this method compares the hash values instead of the whole ﬁles so that it will be more efficient, Audio fingerprinting is the process of representing an audio signal in a compact way by extracting relevant features of the audio content.The fingerprints from the unknown sample are matched against a large set of fingerprints stored in the database. In this our model we are using mysql as the database.Companies like shazam, phillips, intrasonics and many more use audio fingerprinting for various implementations.",
      "project_tags": "python, webdev, html, css",
      "project_body": "# Audio Fingerprinting\r\n\r\n\r\n## ABSTRACT\r\nRecognizing a song from a large cluster of audio can't be achieved by using brute force to compare an audio sample to every song in the database. In this project we use hashing,a process in which reproducible hash tokens are extracted to save the effort, this method compares the hash values instead of the whole ﬁles so that it will be more efficient, Audio fingerprinting is the process of representing an audio signal in a compact way by extracting relevant features of the audio content.The fingerprints from the unknown sample are matched against a large set of fingerprints stored in the database. In this our model we are using mysql as the database.Companies like shazam, phillips, intrasonics and many more use audio fingerprinting for various implementations.\r\n\r\n## AUDIO RECOGNITION\r\nRead the audio file recorded and store it into a 2-D array of amplitude against time.The recording can be done using the microphone or the input file can be read from the system itself and saved as an audio file.This process is same for both , adding the audio files to the database as well as for recognising the audio files i.e both training and testing phase.\r\n\r\n\r\n## Fast Fourier Transform (FFT)\r\nNow we use Fast Fourier Transform (FFT) to change the waveform to frequency domain from time domain.\r\n\r\n\r\n## Spectrogram\r\nNext step is to perform Short-Term Fourier Transform (STFT) of the audio signal by breaking down the signal into small chunks and performing the Fourier Transform on each of them to generate the spectrogram, which is a visual plot of all three variables amplitude against time and frequency.\r\n\r\n\r\n## Mapping peaks\r\nThe processing is usually carried out on a 2-D array , which stores the STFT coefficients of the file and the peaks, local maxima points of the file, which are mapped by masking.A set of the peak and its neighbour are passed to a hash function to generate a hash. A hash is an encoded string which is unique for each input. An audio fingerprint is generated which is a set of hash values and the offset value(time component of the peak).This value is stored in the database with a unique song_id. After we perform these steps on the known file we can match the audio file.\r\n\r\n## Recognise the song\r\nWe recognise the song by comparing the hash value from the database.A pair of key-value is appended into an empty dictionary created for each song. Where key is the difference between the database offset and the sample offset and value if the number of repetitions of the matches we get while comparing the hash values. A score is calculated for each song which is the maximum value of ‘value’ in that particular dictionary. The song with maximum score is the best match for the input file and the model returns the song name with the score value.\r\n\r\n## Conclusion\r\nThe model has been successful in recognizing the song by finding the fingerprints. The further improvements for this model would be to use noise filter techniques, get accurate fingerprints and improve the database.\r\n\r\n## RESOURCES\r\n- [https://medium.com/swlh/understanding-audio-fingerprinting-b39682aa3b5f](https://medium.com/swlh/understanding-audio-fingerprinting-b39682aa3b5f)\r\n- [https://ourcodeworld.com/articles/read/973/creating-your-own-shazam-identify-songs-with-python-through-audio-fingerprinting-in-ubuntu-18-04](https://ourcodeworld.com/articles/read/973/creating-your-own-shazam-identify-songs-with-python-through-audio-fingerprinting-in-ubuntu-18-04)"
    },
    {
      "id": 13,
      "meta": {
        "type": "projects.ProjectsPage",
        "detail_url": "http://localhost/api/v2/pages/13/",
        "html_url": "http://localhost/projects/audio-to-sign-language-translator/",
        "slug": "audio-to-sign-language-translator",
        "show_in_menus": false,
        "seo_title": "",
        "search_description": "",
        "first_published_at": "2024-01-29T15:28:26.615757Z",
        "alias_of": null,
        "locale": "en"
      },
      "title": "Audio to Sign Language Translator",
      "project_title": "Audio to Sign Language Translator",
      "project_sig": "CIPHER",
      "project_slug": "audiotosignlanguagetranslator",
      "project_authors": "Sai, Ayush, Rehan, Yash",
      "github_url": "https://github.com/creativetimofficial/soft-ui-design-system",
      "project_img_url": "https://images.unsplash.com/photo-1577401159468-3bbc7ee440b5?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D",
      "project_description": "Sign languages are visual languages that use hand, facial and body movements as a means of communication. There are over 135 different sign languages all around the world including American Sign Language (ASL), Indian Sign Language (ISL) and British Sign Language (BSL). Sign languages are an extremely important communication tool for many deaf and hard-of-hearing people.  Sign languages are the native languages of the Deaf community and provide full access to communication. Although sign languages are used primarily by people who are deaf, they are also used by others, such as people who can hear but can’t speak. Conversion of audio to ISL helps the common folks to interact with people with such disabilities without the language barrier, enriching both of their lives.",
      "project_tags": "python, css, html",
      "project_body": "## Methodology\r\n- Audio input on the platform using Python Speech Recognition module.\r\n- Conversion of audio to text using Google Speech API.\r\n- Dependency parser for analysing grammatical structure of the sentence and establishing relationship between words.\r\n- ISL Generator: ISL of input sentence using ISL grammar rules.\r\n- Generation of Sign language with concatenating videos\r\n\r\n## Libraries used\r\n- streamlit\r\n- speech_recognition\r\n- cv2\r\n- numpy\r\n- moviepy\r\n- nltk\r\n\r\n## Timeline\r\n\r\n| **STEP** | **TIME NEEDED** |\r\n| --- | ----------- |\r\n| Learning process | 35 days |\r\n| Working on theory to design | 15 days |\r\n| Designing the model/Coding | 25 days |\r\n| Working on changes and simulations\t | 10 days |\r\n| Analysis | 2 days |\r\n\r\n## Challenges\r\n- Compiling a quality repository of words and alphabets for output video.\r\n- Time required in processing video."
    }
  ]
}